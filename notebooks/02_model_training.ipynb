{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "d0cd93b9",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Trouvé 11 fichiers. Fusion en cours...\n",
                        "\n",
                        "--- Résumé des données chargées ---\n",
                        "Nombre d'actifs (N) : 197\n",
                        "Nombre de jours (T) : 1120\n",
                        "Aperçu des 3 premières lignes :\n",
                        "                GOOGL        META         DIS       NFLX         VZ  \\\n",
                        "Date                                                                  \n",
                        "2020-09-16  75.086624  261.905426  129.924072  48.386002  44.270195   \n",
                        "2020-09-17  73.842697  253.258759  128.084747  47.020000  44.431526   \n",
                        "2020-09-18  72.057510  250.982758  126.520805  46.995998  44.255527   \n",
                        "\n",
                        "                    T        TMUS      CMCSA        CHTR          EA  ...  \\\n",
                        "Date                                                                  ...   \n",
                        "2020-09-16  15.401609  109.904205  40.505207  630.070007  123.228508  ...   \n",
                        "2020-09-17  15.312070  108.116905  39.440876  620.309998  121.789543  ...   \n",
                        "2020-09-18  15.238322  106.967239  39.163971  625.250000  122.411789  ...   \n",
                        "\n",
                        "                 WELL        EQIX        NEE        DUK         SO          D  \\\n",
                        "Date                                                                            \n",
                        "2020-09-16  51.815319  694.452332  61.387398  69.049728  43.662182  65.717773   \n",
                        "2020-09-17  50.006500  683.872742  61.205658  68.854393  43.850636  64.284218   \n",
                        "2020-09-18  48.855434  680.632568  60.636353  67.511497  43.268921  62.786236   \n",
                        "\n",
                        "                  AEP        EXC        SRE        XEL  \n",
                        "Date                                                    \n",
                        "2020-09-16  66.453499  21.471830  51.006439  60.580441  \n",
                        "2020-09-17  66.106628  21.276421  51.086643  58.462013  \n",
                        "2020-09-18  65.065971  20.767155  50.643440  57.146523  \n",
                        "\n",
                        "[3 rows x 197 columns]\n",
                        "\n",
                        "--- Prêt pour l'optimisation ---\n",
                        "Forme de mu : (197,)\n",
                        "Forme de Sigma : (197, 197)\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import os\n",
                "import glob\n",
                "\n",
                "def load_and_merge_data(folder_path):\n",
                "    all_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
                "    df_list = []\n",
                "    sector_map = {} # Pour garder en mémoire quel actif appartient à quel secteur (utile pour Streamlit plus tard)\n",
                "    print(f\"Trouvé {len(all_files)} fichiers. Fusion en cours...\")\n",
                "\n",
                "    for filename in all_files:\n",
                "        # Récupérer le nom du secteur depuis le nom du fichier (ex: 'Energy.csv' -> 'Energy')\n",
                "        sector_name = os.path.basename(filename).replace('.csv', '')\n",
                "        \n",
                "        # 2. Lire le CSV en mettant la Date en index directement\n",
                "        # parse_dates=True permet de comprendre que c'est une date temporelle\n",
                "        df_temp = pd.read_csv(filename, parse_dates=['Date'], index_col='Date')\n",
                "        \n",
                "        # Petit nettoyage : on s'assure que ce sont des nombres\n",
                "        df_temp = df_temp.apply(pd.to_numeric, errors='coerce')\n",
                "        \n",
                "        # Sauvegarder le secteur de chaque actif (Bonus pour la suite du projet)\n",
                "        for asset in df_temp.columns:\n",
                "            sector_map[asset] = sector_name\n",
                "            \n",
                "        df_list.append(df_temp)\n",
                "\n",
                "    # 3. Concaténation horizontale (axis=1)\n",
                "    # Pandas aligne tout seul sur l'index 'Date'. Pas de doublons de colonne Date.\n",
                "    full_price_data = pd.concat(df_list, axis=1)\n",
                "    \n",
                "    # 4. Nettoyage des données manquantes (Indispensable pour l'optimisation)\n",
                "    # Si un actif a des trous, on remplit avec la valeur précédente (ffill) puis on supprime les lignes vides restantes\n",
                "    full_price_data = full_price_data.ffill().dropna()\n",
                "\n",
                "    return full_price_data, sector_map\n",
                "\n",
                "# Chemin vers ton dossier 'data' (adapte le chemin si besoin)\n",
                "folder_path = '../data' \n",
                "\n",
                "# 1. Récupération des prix fusionnés\n",
                "prices_df, sector_info = load_and_merge_data(folder_path)\n",
                "\n",
                "print(\"\\n--- Résumé des données chargées ---\")\n",
                "print(f\"Nombre d'actifs (N) : {prices_df.shape[1]}\")\n",
                "print(f\"Nombre de jours (T) : {prices_df.shape[0]}\")\n",
                "print(\"Aperçu des 3 premières lignes :\")\n",
                "print(prices_df.head(3))\n",
                "\n",
                "# --- PRÉPARATION POUR L'ALGO (Partie 1) ---\n",
                "\n",
                "# 2. Calcul des Rendements (Returns)\n",
                "# L'optimisation de Markowitz se fait sur les rendements, pas sur les prix bruts.\n",
                "# pct_change() calcule (Prix_t - Prix_t-1) / Prix_t-1\n",
                "returns_df = prices_df.pct_change().dropna()\n",
                "\n",
                "# 3. Calcul des inputs mathématiques pour ton algo convexe\n",
                "mu = returns_df.mean().values  # Vecteur des rendements moyens espérés\n",
                "Sigma = returns_df.cov().values # Matrice de covariance\n",
                "\n",
                "print(\"\\n--- Prêt pour l'optimisation ---\")\n",
                "print(f\"Forme de mu : {mu.shape}\")\n",
                "print(f\"Forme de Sigma : {Sigma.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c2d4afd9",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- Optimisation en cours (Scalarisation) ---\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import scipy.optimize as sco\n",
                "import glob\n",
                "import os\n",
                "\n",
                "# ==========================================\n",
                "# 1. CHARGEMENT ET FUSION DES DONNÉES\n",
                "# ==========================================\n",
                "def load_data(folder_path='data'):\n",
                "    print(\"--- Chargement des fichiers ---\")\n",
                "    all_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
                "    \n",
                "    if not all_files:\n",
                "        raise FileNotFoundError(f\"Aucun fichier CSV trouvé dans '{folder_path}'\")\n",
                "        \n",
                "    df_list = []\n",
                "    \n",
                "    for filename in all_files:\n",
                "        # Lire le fichier, mettre la Date en index\n",
                "        df = pd.read_csv(filename, parse_dates=['Date'], index_col='Date')\n",
                "        \n",
                "        # Nettoyage : conversion en numérique au cas où\n",
                "        df = df.apply(pd.to_numeric, errors='coerce')\n",
                "        \n",
                "        # On ajoute au tableau\n",
                "        df_list.append(df)\n",
                "        print(f\"Chargé : {os.path.basename(filename)} ({df.shape[1]} actifs)\")\n",
                "\n",
                "    # Fusion sur l'index (Date)\n",
                "    full_df = pd.concat(df_list, axis=1)\n",
                "    \n",
                "    # Nettoyage des données manquantes (Forward Fill puis Drop)\n",
                "    full_df = full_df.ffill().dropna()\n",
                "    \n",
                "    print(f\"\\nDonnées fusionnées : {full_df.shape[1]} actifs sur {full_df.shape[0]} jours.\")\n",
                "    return full_df\n",
                "\n",
                "# ==========================================\n",
                "# 2. PRÉPARATION MATHEMATIQUE (Mu & Sigma)\n",
                "# ==========================================\n",
                "\n",
                "# Calcul des Rendements (Returns) : (Prix_t - Prix_t-1) / Prix_t-1\n",
                "returns_df = prices_df.pct_change().dropna()\n",
                "\n",
                "# Vectorisation pour l'optimiseur\n",
                "mu = returns_df.mean().values * 252  # Annualisation (facultatif mais standard)\n",
                "Sigma = returns_df.cov().values * 252 # Annualisation\n",
                "\n",
                "n_assets = len(mu)\n",
                "asset_names = returns_df.columns.tolist()\n",
                "\n",
                "# ==========================================\n",
                "# 3. MOTEUR D'OPTIMISATION CONVEXE (SCIPY)\n",
                "# ==========================================\n",
                "\n",
                "def portfolio_stats(weights, mu, Sigma):\n",
                "    \"\"\"Retourne (Rendement, Risque/Variance)\"\"\"\n",
                "    p_ret = np.dot(weights, mu)\n",
                "    # Formule du risque quadratique w^T * Sigma * w [cite: 84]\n",
                "    p_var = np.dot(weights.T, np.dot(Sigma, weights)) \n",
                "    return p_ret, p_var\n",
                "\n",
                "def scalarized_objective(weights, mu, Sigma, lambd):\n",
                "    \"\"\"\n",
                "    Fonction objectif scalaire \n",
                "    Minimiser: lambda * Risque - (1 - lambda) * Rendement\n",
                "    \"\"\"\n",
                "    ret, var = portfolio_stats(weights, mu, Sigma)\n",
                "    # On minimise, donc on inverse le signe du rendement\n",
                "    return lambd * var - (1 - lambd) * ret\n",
                "\n",
                "# Configuration du solveur\n",
                "bounds = tuple((0, 1) for _ in range(n_assets)) # Pas de vente à découvert (Poids >= 0) [cite: 107]\n",
                "constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1}) # Somme des poids = 1 [cite: 104]\n",
                "init_guess = np.array([1/n_assets] * n_assets) # Départ équiréparti\n",
                "\n",
                "# ==========================================\n",
                "# 4. CALCUL DE LA FRONTIÈRE EFFICIENTE\n",
                "# ==========================================\n",
                "print(\"\\n--- Optimisation en cours (Scalarisation) ---\")\n",
                "\n",
                "pareto_risks = []\n",
                "pareto_returns = []\n",
                "pareto_weights = []\n",
                "\n",
                "# On balaie lambda de 0 (Max Rendement) à 1 (Min Risque)\n",
                "lambdas = np.linspace(0, 1, 50) \n",
                "\n",
                "for l in lambdas:\n",
                "    res = sco.minimize(\n",
                "        scalarized_objective,\n",
                "        init_guess,\n",
                "        args=(mu, Sigma, l),\n",
                "        method='SLSQP', # Solveur pour problèmes convexes contraints [cite: 1018]\n",
                "        bounds=bounds,\n",
                "        constraints=constraints\n",
                "    )\n",
                "    \n",
                "    if res.success:\n",
                "        r, v = portfolio_stats(res.x, mu, Sigma)\n",
                "        pareto_returns.append(r)\n",
                "        pareto_risks.append(v)\n",
                "        pareto_weights.append(res.x)\n",
                "\n",
                "print(\"Optimisation terminée.\")\n",
                "\n",
                "# ==========================================\n",
                "# 5. VISUALISATION (LIVRABLES)\n",
                "# ==========================================\n",
                "\n",
                "# Graphique 1 : Frontière Efficiente\n",
                "plt.figure(figsize=(12, 6))\n",
                "plt.scatter(pareto_risks, pareto_returns, c=lambdas, cmap='viridis', marker='o')\n",
                "plt.title('Frontière Efficiente (Modèle de Markowitz Convexe)')\n",
                "plt.xlabel('Risque (Variance Portefeuille) $f_2$')\n",
                "plt.ylabel('Rendement Espéré (Annualisé) $f_1$')\n",
                "plt.colorbar(label='Paramètre de préférence $\\lambda$ (0=Audacieux, 1=Prudent)')\n",
                "plt.grid(True, linestyle='--', alpha=0.5)\n",
                "\n",
                "# Afficher les points extrêmes\n",
                "min_risk_idx = np.argmin(pareto_risks)\n",
                "max_ret_idx = np.argmax(pareto_returns)\n",
                "plt.scatter(pareto_risks[min_risk_idx], pareto_returns[min_risk_idx], c='red', s=200, marker='*', label='Min Variance')\n",
                "plt.scatter(pareto_risks[max_ret_idx], pareto_returns[max_ret_idx], c='green', s=200, marker='*', label='Max Rendement')\n",
                "plt.legend()\n",
                "plt.show()\n",
                "\n",
                "# Graphique 2 : Composition (Stacked Plot)\n",
                "# Attention: Avec beaucoup d'actifs, ce graphe est dense. On affiche tout de même.\n",
                "weights_df = pd.DataFrame(pareto_weights, columns=asset_names)\n",
                "weights_df['Risque'] = pareto_risks\n",
                "weights_df = weights_df.sort_values('Risque')\n",
                "\n",
                "# Pour la lisibilité, on ne garde que les actifs qui dépassent 1% du portefeuille à un moment donné\n",
                "active_assets = weights_df.drop('Risque', axis=1).max() > 0.01\n",
                "filtered_weights = weights_df.loc[:, active_assets]\n",
                "remaining_weights = 1 - filtered_weights.sum(axis=1)\n",
                "\n",
                "plt.figure(figsize=(12, 6))\n",
                "plt.stackplot(weights_df['Risque'], filtered_weights.T, labels=filtered_weights.columns, alpha=0.8)\n",
                "plt.title('Allocation d\\'actifs le long de la frontière (Actifs principaux > 1%)')\n",
                "plt.xlabel('Niveau de Risque')\n",
                "plt.ylabel('Proportion dans le portefeuille')\n",
                "plt.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv (3.13.9)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
